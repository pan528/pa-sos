# gpt的指导
## 损失函数设计：**如何结合 L2（MSE）损失 和 SSIM 损失？**
为了同时 **确保预测图像的数值精度** 并 **增强边缘细节、减少模糊效应**，可以采用 **加权组合损失函数**：

#### **1. 组合损失公式**
\[
L_{\text{total}} = \alpha L_{\text{MSE}} + \beta (1 - SSIM(x, y))
\]
其中：
- **L2（MSE）损失**：
  \[
  L_{\text{MSE}} = \frac{1}{N} \sum (x - y)^2
  \]
  - 确保预测图像的 **数值精度**，避免整体偏差。
  - **适用于超声图像的像素级误差度量**。

- **SSIM（结构相似性）损失**：
  \[
  L_{\text{SSIM}} = 1 - SSIM(x, y)
  \]
  - 确保 **边缘结构信息**，避免模糊效应。
  - **增强图像局部对比度**，提高视觉质量。

- **超参数 \( \alpha, \beta \)**：
  - **如果更关注整体误差**（数值精度），则让 **\( \alpha > \beta \)**。
  - **如果更关注边缘清晰度**（避免模糊），则让 **\( \beta > \alpha \)**。

---

### **2. PyTorch 代码实现**
```python
import torch
import torch.nn as nn
import torch.nn.functional as F

# SSIM 计算函数
def ssim_loss(img1, img2, window_size=11, size_average=True):
    C1 = 0.01 ** 2
    C2 = 0.03 ** 2

    mu1 = F.avg_pool2d(img1, kernel_size=window_size, stride=1, padding=window_size//2)
    mu2 = F.avg_pool2d(img2, kernel_size=window_size, stride=1, padding=window_size//2)

    mu1_sq, mu2_sq, mu1_mu2 = mu1 ** 2, mu2 ** 2, mu1 * mu2
    sigma1_sq = F.avg_pool2d(img1 ** 2, kernel_size=window_size, stride=1, padding=window_size//2) - mu1_sq
    sigma2_sq = F.avg_pool2d(img2 ** 2, kernel_size=window_size, stride=1, padding=window_size//2) - mu2_sq
    sigma12 = F.avg_pool2d(img1 * img2, kernel_size=window_size, stride=1, padding=window_size//2) - mu1_mu2

    ssim_map = ((2 * mu1_mu2 + C1) * (2 * sigma12 + C2)) / ((mu1_sq + mu2_sq + C1) * (sigma1_sq + sigma2_sq + C2))

    return ssim_map.mean() if size_average else ssim_map

# 组合损失函数
class MSE_SSIM_Loss(nn.Module):
    def __init__(self, alpha=0.5, beta=0.5):
        super(MSE_SSIM_Loss, self).__init__()
        self.alpha = alpha
        self.beta = beta
        self.mse = nn.MSELoss()

    def forward(self, pred, target):
        mse_loss = self.mse(pred, target)
        ssim_val = ssim_loss(pred, target)
        total_loss = self.alpha * mse_loss + self.beta * (1 - ssim_val)
        return total_loss

# 示例：使用损失函数
loss_fn = MSE_SSIM_Loss(alpha=0.5, beta=0.5)
pred = torch.rand(1, 1, 384, 384)  # 假设输出图像
target = torch.rand(1, 1, 384, 384)  # 真实声速图
loss = loss_fn(pred, target)
print("Loss:", loss.item())
```

---

### **3. 如何应用到模型训练？**
```python
# 定义模型
model = YourModel()
optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)
loss_fn = MSE_SSIM_Loss(alpha=0.5, beta=0.5)

# 训练循环
for epoch in range(num_epochs):
    for batch in dataloader:
        inputs, targets = batch  # inputs: (128, 1024), targets: (384, 384)

        # 前向传播
        preds = model(inputs)
        loss = loss_fn(preds, targets)

        # 反向传播
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

    print(f"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item()}")
```

---

### **4. 适用场景**
✅ **医学图像重建（光声/超声）**  
✅ **超声信号 → 2D 声速图转换**  
✅ **提高边缘清晰度 & 保持数值稳定性**  

---

### **5. 总结**
- **MSE（L2）保证数值精度**，减少像素级误差。
- **SSIM 关注结构完整性**，减少模糊，提高边缘细节。
- **适用于超声/光声/CT 等图像重建任务**，增强视觉和数值质量。

  
# 实验
## 引入TV损失
TV 损失的作用：通过减少相邻像素之间的差异，平滑预测结果，减少噪声。
```python
from tensorflow.keras.losses import Loss
from tensorflow.keras.losses import Huber
import tensorflow as tf

def total_variation_loss(y_pred):
    """
    计算总变差（TV）损失。
    :param y_pred: 模型的预测输出（通常是图像）。
    :return: TV 损失值。
    """
    return tf.reduce_sum(tf.image.total_variation(y_pred))

# 自定义损失类
class CombinedLoss(Loss):
    def __init__(self, delta=1.0, tv_weight=1e-6):
        super(CombinedLoss, self).__init__()
        self.delta = delta
        self.tv_weight = tv_weight
        self.huber_loss = Huber(delta=self.delta)

    def call(self, y_true, y_pred):
        # Huber 损失
        huber_loss = self.huber_loss(y_true, y_pred)
        # TV 损失
        tv_loss = total_variation_loss(y_pred)
        # 总损失
        return huber_loss + self.tv_weight * tv_loss
```
## SSIM损失
